{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pose_Estimation_2_Intro_to_CNNS",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOU5sCc480I44mo/W0i7zwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e46e168a6e614cc8bebbbce3aca3d497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e27b6c3dc9d4eb4add4d2e9b69d4719",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_78c28ff837e14b7795665b229cf0e439",
              "IPY_MODEL_cd60462ed2ad42cbb48e8663d7c70fbc"
            ]
          }
        },
        "6e27b6c3dc9d4eb4add4d2e9b69d4719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78c28ff837e14b7795665b229cf0e439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_180bbfeaf5894de58533a0dcd1a25c4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af52f1038f9d43cfbc7cbbd4b18ae4e1"
          }
        },
        "cd60462ed2ad42cbb48e8663d7c70fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_293f87ead2074f71877a4a40414de089",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "182042624it [00:30, 17180556.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc712789d7d54cd597a948a5924fb9b9"
          }
        },
        "180bbfeaf5894de58533a0dcd1a25c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af52f1038f9d43cfbc7cbbd4b18ae4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "293f87ead2074f71877a4a40414de089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc712789d7d54cd597a948a5924fb9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5144a3ba176d4feb9b4137f6ca405afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48009b20e5c648fd89931e2991d1a996",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_efe48f0fb53f4a8f9a690d0c7d3cdd97",
              "IPY_MODEL_003cadc8d350477d9e329389adf89c13"
            ]
          }
        },
        "48009b20e5c648fd89931e2991d1a996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "efe48f0fb53f4a8f9a690d0c7d3cdd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b593b4d31254755a94a6b53d876ac9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59b5df7fed1c421a8e568ff8d2513623"
          }
        },
        "003cadc8d350477d9e329389adf89c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e66ee43a01a4e31b9a1b409cfe124df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "64282624it [00:00, 81295019.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_246c62ccd11b42938537baa844744d52"
          }
        },
        "3b593b4d31254755a94a6b53d876ac9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59b5df7fed1c421a8e568ff8d2513623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e66ee43a01a4e31b9a1b409cfe124df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "246c62ccd11b42938537baa844744d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lollipopenator/Manning/blob/master/Pose_Estimation_2_Intro_to_CNNS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgMA3eo7PeDC",
        "colab_type": "text"
      },
      "source": [
        "Following Tutorial at https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py\n",
        "\n",
        "\n",
        "Some other models I looked at:\n",
        "\n",
        "https://github.com/potterhsu/SVHNClassifier-PyTorch/blob/master/model.py (I used hyperparameters from here)\n",
        "\n",
        "https://github.com/blaueck/pytorch-demo/blob/master/models/simple_cnn.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAhsA32OnMoi",
        "colab_type": "text"
      },
      "source": [
        "# Start SVHN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LfWrUcKsFR0l",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import logging\n",
        "logging.basicConfig()\n",
        "\n",
        "# creates a new logger called 'SVHN_logger'\n",
        "# Future calls to getLogger with this name will always return the same instance,\n",
        "svhn_logger = logging.getLogger('SVHN_logger')\n",
        "\n",
        "######## Select an option below for logging level ########\n",
        "# The loggoinmg level can also be set later in the code,  just prior to where\n",
        "# you want to  enable logging.\n",
        "# \n",
        "# svhn_logger.setLevel(logging.DEBUG) \n",
        "# the above will log all messages (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
        "\n",
        "\n",
        "svhn_logger.setLevel(logging.INFO) \n",
        "# the above will only log messages at level INFO and higher (basically shuts off all my\n",
        "# verbose debug output)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0a5Jq7Dojzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download the train and test datasets\n",
        "# !wget http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
        "# !wget http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-j9I1IKXL63",
        "colab_type": "text"
      },
      "source": [
        "Setup Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwgNn_hlQ9Cs",
        "colab_type": "text"
      },
      "source": [
        "The below is from https://forums.fast.ai/t/image-normalization-in-pytorch/7534\n",
        "\n",
        "https://forums.fast.ai/t/image-normalization-in-pytorch/7534/6\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "  The code below is inspired by code found in this post:\n",
        "  https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
        "  \n",
        "\n",
        "  wsl_na may also need to divide by 255 as per here: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/9\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GDfHP_UQM1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper function for precalculating the per-channel means and stds over the \n",
        "# entire dataset\n",
        "def get_dataset_mean_and_std():\n",
        "  img_transform = transforms.ToTensor() \n",
        "\n",
        "  # Load the trainset for the purpose of calculating the per-channel mean and std\n",
        "  # over the entire trainset. \n",
        "  # We will pass these values (dataset mean/std) into \n",
        "  # the per-image transform when we later load the testset to do some actual \n",
        "  # work.\n",
        "  # On this first load of the data we only use the ToTensor() transform \n",
        "  # and no other transforms, as the whole point of this bit is to find the values \n",
        "  # we are going to use later in the per-image transform.\n",
        "  trainset = torchvision.datasets.SVHN(root='/content', split='train', \n",
        "                                    transform=transforms.ToTensor(),\n",
        "                                    download=True)\n",
        "\n",
        "  svhn_logger.debug('In get_dataset_mean_and_std(): loaded testset to calculate per-dataset mean and std...')\n",
        "\n",
        "  import numpy as np\n",
        "\n",
        "\n",
        "  loader = torch.utils.data.DataLoader(trainset, batch_size=4096, shuffle=False, num_workers=4)\n",
        "\n",
        "  pop_mean = []\n",
        "  pop_std0 = []\n",
        "\n",
        "  for i, data in enumerate(loader, 0):\n",
        "\n",
        "      # shape (batch_size, 3, height, width)\n",
        "      numpy_image = data[0].numpy()\n",
        "      \n",
        "      # shape (3,)\n",
        "      batch_mean = np.mean(numpy_image, axis=(0,2,3))\n",
        "      batch_std0 = np.std(numpy_image, axis=(0,2,3))\n",
        "  \n",
        "      \n",
        "      pop_mean.append(batch_mean)\n",
        "      pop_std0.append(batch_std0)\n",
        "  \n",
        "\n",
        "  # # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
        "  pop_mean = np.array(pop_mean).mean(axis=0)\n",
        "  pop_std0 = np.array(pop_std0).mean(axis=0)\n",
        "\n",
        "  svhn_logger.debug('len(trainset): %s', len(trainset))\n",
        "  svhn_logger.debug('len(trainset)/batch_size: %s', len(trainset)/4096)\n",
        "  svhn_logger.debug('i: %s', i)\n",
        "  svhn_logger.debug('pop_mean: %s', pop_mean)\n",
        "  svhn_logger.debug('pop_std0: %s', pop_std0)\n",
        "\n",
        "  svhn_logger.info('Finished calulating per-channel means and stds over entire testset...')\n",
        "  return ({'mean': pop_mean, 'std': pop_std0})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQpeNp9xWzN1",
        "colab_type": "text"
      },
      "source": [
        "Create dataset using transforms, then create dataloader,  and also do a couple of quick tests/views of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xasksmPFnQXi",
        "colab_type": "code",
        "outputId": "497ca228-783f-40f7-f0ef-6832a0579d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "e46e168a6e614cc8bebbbce3aca3d497",
            "6e27b6c3dc9d4eb4add4d2e9b69d4719",
            "78c28ff837e14b7795665b229cf0e439",
            "cd60462ed2ad42cbb48e8663d7c70fbc",
            "180bbfeaf5894de58533a0dcd1a25c4e",
            "af52f1038f9d43cfbc7cbbd4b18ae4e1",
            "293f87ead2074f71877a4a40414de089",
            "bc712789d7d54cd597a948a5924fb9b9",
            "5144a3ba176d4feb9b4137f6ca405afb",
            "48009b20e5c648fd89931e2991d1a996",
            "efe48f0fb53f4a8f9a690d0c7d3cdd97",
            "003cadc8d350477d9e329389adf89c13",
            "3b593b4d31254755a94a6b53d876ac9f",
            "59b5df7fed1c421a8e568ff8d2513623",
            "2e66ee43a01a4e31b9a1b409cfe124df",
            "246c62ccd11b42938537baa844744d52"
          ]
        }
      },
      "source": [
        "# wsl_na check what 'shuffle' value is best\n",
        "\n",
        "# wsl revert to batch_size = 4 when ready. \n",
        "my_batch_size = 4\n",
        "\n",
        "# now that we have the per-channel mean and std over the entire dataset, we\n",
        "# can pass it into the Normalize(..) transform which will be applied to each \n",
        "# image as it is loaded.\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(**get_dataset_mean_and_std())\n",
        "])\n",
        "\n",
        "######## Training Data\n",
        "trainset = torchvision.datasets.SVHN(root='/content', split='train', \n",
        "                                    transform=img_transform, target_transform=None,\n",
        "                                    download=True)\n",
        "svhn_logger.info('created trainset')\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = my_batch_size,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "svhn_logger.info('created trainloader')\n",
        "\n",
        "\n",
        "######## Test Data\n",
        "testset = torchvision.datasets.SVHN(root='/content', split='test', \n",
        "                                    transform=img_transform, target_transform=None,\n",
        "                                    download=True)\n",
        "svhn_logger.info('created testset')\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = my_batch_size,\n",
        "                                         shuffle=True, num_workers=2)\n",
        "svhn_logger.info('created testloader')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /content/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e46e168a6e614cc8bebbbce3aca3d497",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:SVHN_logger:Finished calulating per-channel means and stds over entire testset...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /content/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:SVHN_logger:created trainset\n",
            "INFO:SVHN_logger:created trainloader\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to /content/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5144a3ba176d4feb9b4137f6ca405afb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:SVHN_logger:created testset\n",
            "INFO:SVHN_logger:created testloader\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFHI5pVi8osR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "These means are over the entire image, rather than per RGB color-channel\n",
        "However they still give a general idea whether the values are between \n",
        "approximately -3 and +3, which is where they ought to be after standardisation.\n",
        "\n",
        "See ie https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w2hTPU3r4U5",
        "colab_type": "code",
        "outputId": "56577110-1007-430b-a3df-79eb3dd6c981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# matplotlib was giving too many info- and debug- level logs.\n",
        "# grab an instance of its logger and set it to warnings only.\n",
        "logging.getLogger(plt.__name__).setLevel(logging.WARNING)\n",
        "\n",
        "\n",
        "# functions to show an image and to provide general info about it\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # roughly unnormalize # wsl maybe fix\n",
        "    img = img.cpu() # Needed when running on GPU\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def image_info(img):\n",
        "    # Main info about this image\n",
        "    print('image_info: img.shape: %s', img.shape)\n",
        "\n",
        "    # additional info which may sometimes be needed is below\n",
        "    # these means are over the entire image, rather than per RGB color-channel\n",
        "    # (see notes above as to why)\n",
        "    svhn_logger.debug('image_info: img.mean(): %s', img.mean())\n",
        "    svhn_logger.debug('image_info: ----------------------------------img.min(): %s', img.min())\n",
        "    svhn_logger.debug('image_infoL----------------------------------------------------------------img.max(): %s', img.max())\n",
        "\n",
        "    # uncomment to show the mean per RGB channel\n",
        "    # logger.debug('image_info: img.mean(): %s', img.mean(axis=(1,2)))\n",
        "\n",
        "\n",
        "# get some random training images and display them (and associated labels)\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "\n",
        "for image in images:\n",
        "  image_info(image)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(my_batch_size))) # wsl revert to 4\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image_info: img.shape: %s torch.Size([3, 32, 32])\n",
            "image_info: img.shape: %s torch.Size([3, 32, 32])\n",
            "image_info: img.shape: %s torch.Size([3, 32, 32])\n",
            "image_info: img.shape: %s torch.Size([3, 32, 32])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0Qe4oihKRtEHuKIoSkbRB7iiKEpG+f85mwD+JpMa+AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:  tensor(4) tensor(3) tensor(5) tensor(0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shQt-FdEQUGS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Define a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh36vsV45xdg",
        "colab_type": "text"
      },
      "source": [
        "https://discuss.pytorch.org/t/is-there-similar-pytorch-function-as-model-summary-as-keras/2678/5\n",
        "\n",
        "How to work out the correct parameters for the fc layer at the end.:\n",
        "```\n",
        "from torchsummary import summary\n",
        "summary(net, (3, 32, 32))\n",
        "```\n",
        "\n",
        "where (3, 32, 32) is the input shape, which needs to be known in advance. The output size of the following layers given this input will be displayed by the summary(..) call, in the same format as that used in KERAS.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#batchnorm2d\n",
        "\n",
        "See also discussion here:\n",
        "https://discuss.pytorch.org/t/example-on-how-to-use-batch-norm/216\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "I tried out hyper-parameters from first three layers of networks here:\n",
        " https://github.com/potterhsu/SVHNClassifier-PyTorch/blob/master/model.py\n",
        " https://github.com/blaueck/pytorch-demo/blob/master/models/simple_cnn.py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X3kNGJUDV_b",
        "colab_type": "code",
        "outputId": "2ea4ddf0-af98-4b2f-bdbe-5050bd8906ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM2WHEhdQYSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "# wsl_na\n",
        "# Initialize the weights of the convolutioanl layers with a normal distribution \n",
        "# with std=0.001, and their biases with a constant value of 0\n",
        "# wsl_na move to gpu\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Three convolutional layers with batchnorm, maxpooling, and \n",
        "        # ReLU activation.\n",
        "        self._hidden1 = nn.Sequential(\n",
        "            nn.Conv2d(kernel_size=5, in_channels=3, out_channels=48, stride=1, padding=4),\n",
        "            nn.BatchNorm2d(num_features=48),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            # nn.Dropout(0.2)\n",
        "        )\n",
        "        self._hidden2 = nn.Sequential(\n",
        "            nn.Conv2d(kernel_size=3, in_channels=48, out_channels=64, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(num_features=64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            # nn.Dropout(0.2)\n",
        "        )\n",
        "        self._hidden3 = nn.Sequential(\n",
        "            nn.Conv2d(kernel_size=3, in_channels=64, out_channels=128, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            # nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "        # A single fully-connected layer at the end  \n",
        "        self.fc = nn.Linear(128 * 6 * 6, 10)\n",
        "       \n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self._hidden1(x)\n",
        "        x = self._hidden2(x)\n",
        "        x = self._hidden3(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 6 * 6)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "\n",
        "\n",
        "# from torchsummary import summary\n",
        "# summary(net, (3, 32, 32))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJdguGFfQrnN",
        "colab_type": "text"
      },
      "source": [
        "## 3. Define a Loss function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezKLsC24QthP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1i6mk0ayQ8p2",
        "colab_type": "text"
      },
      "source": [
        "## 4. Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEf-9cjARFlz",
        "colab_type": "code",
        "outputId": "4923d7aa-df20-4cf6-dc26-96f9fbb5beef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "\n",
        "\n",
        "# Training Loop: Now it is time to define the training procedure. Again, you can follow closely the pytorch tutorial:\n",
        "\n",
        "# loss function: Use Softmax-Crossentropy (torch.nn.CrossEntropyLoss) for classification\n",
        "# optimizer: the Adam optimizer is often a good starting point.\n",
        "\n",
        "# Print out the loss periodically, so you can monitor the training progress. For bigger tasks, you can look into Tensorboard but for our project, we won’t need it.\n",
        "\n",
        "# Also calculate the accuracy on the testset periodically. Sometimes the loss does not decrease, but the accuracy still improves.\n",
        "\n",
        "# Learning rate: Try to find a good learning rate. If it is too big, your loss will increase. If it’s too small, your loss will decrease very slowly or not at all.\n",
        "# Decreasing the learning rate after a few epochs sometimes gives a small boost in the model accuracy.\n",
        "\n",
        "# Batch-size: Generally, the bigger the better. It is usually limited by the GPU memory\n",
        "\n",
        "# Make sure you move the model, the images and the labels to the GPU memory with xx.to(‘cuda’) AND you run model.train() and model.eval() when needed.\n",
        "net.to(device)\n",
        "\n",
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        # inputs, labels = data\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.721\n",
            "[1,  4000] loss: 0.719\n",
            "[1,  6000] loss: 0.578\n",
            "[1,  8000] loss: 0.507\n",
            "[1, 10000] loss: 0.469\n",
            "[1, 12000] loss: 0.439\n",
            "[1, 14000] loss: 0.424\n",
            "[1, 16000] loss: 0.402\n",
            "[1, 18000] loss: 0.375\n",
            "[2,  2000] loss: 0.330\n",
            "[2,  4000] loss: 0.326\n",
            "[2,  6000] loss: 0.339\n",
            "[2,  8000] loss: 0.314\n",
            "[2, 10000] loss: 0.316\n",
            "[2, 12000] loss: 0.308\n",
            "[2, 14000] loss: 0.307\n",
            "[2, 16000] loss: 0.325\n",
            "[2, 18000] loss: 0.327\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JP1OpBJRYcD",
        "colab_type": "text"
      },
      "source": [
        "## 4a. Save the Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9ytJOF1RU4D",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyFA1zR5RVkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "PATH = '/content/svhn.net'\n",
        "torch.save(net.state_dict(), PATH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAuRRt2rRjfJ",
        "colab_type": "text"
      },
      "source": [
        "# 5. Test the network on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUS7ItaGRzxD",
        "colab_type": "code",
        "outputId": "635b54d4-1cc3-425d-994d-08009dedad9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "# images, labels = dataiter.next()\n",
        "data = dataiter.next()\n",
        "images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "# wsl_na fix this!\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAB5CAYAAAAgYXpDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:  tensor(7, device='cuda:0') tensor(3, device='cuda:0') tensor(9, device='cuda:0') tensor(3, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h08Y8FqhSIwS",
        "colab_type": "text"
      },
      "source": [
        "Load the saved model back in ( (note: saving and re-loading the model wasn’t necessary here, we only did it to illustrate how to do so):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D-fcOdBSPef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-D1D2twSYvF",
        "colab_type": "code",
        "outputId": "0b939588-4c0f-48c5-c2ea-6e0c449d049b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Okay, now let us see what the neural network thinks these examples above are:\n",
        "\n",
        "\n",
        "outputs = net(images)\n",
        "# The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % predicted[j]\n",
        "                              for j in range(my_batch_size)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  tensor(7, device='cuda:0') tensor(3, device='cuda:0') tensor(9, device='cuda:0') tensor(1, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co0cv7QHSnmT",
        "colab_type": "code",
        "outputId": "91393b49-49f2-4ad5-f5dc-ebf1b82d47ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# The results seem pretty good.\n",
        "\n",
        "# Let us look at how the network performs on the whole dataset.\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# print('Accuracy of the network on the 10000 test images: %2d %%' % (\n",
        "#     100 * correct / total))\n",
        "\n",
        "print('Accuracy of the network on the %s  test images: %.2f %%' % (len(testset),\n",
        "    100.0000 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 26032  test images: 90.15 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEPke4gXTDh-",
        "colab_type": "text"
      },
      "source": [
        "# On which digits did the network perform best?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ8yfpyOTIR0",
        "colab_type": "code",
        "outputId": "06f3bcf2-0f16-432a-fc9e-3b437e5de20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "correct_per_class = list(0. for i in range(10))\n",
        "total_per_class = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        # images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            correct_per_class[label] += c[i].item()\n",
        "            total_per_class[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        i, 100 * correct_per_class[i] / total_per_class[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of     0 : 93 %\n",
            "Accuracy of     1 : 95 %\n",
            "Accuracy of     2 : 93 %\n",
            "Accuracy of     3 : 80 %\n",
            "Accuracy of     4 : 92 %\n",
            "Accuracy of     5 : 92 %\n",
            "Accuracy of     6 : 85 %\n",
            "Accuracy of     7 : 87 %\n",
            "Accuracy of     8 : 79 %\n",
            "Accuracy of     9 : 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMc_P2udThEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}